---
title: "CourseKata Chapter 6: Part III (Sec 5 to 11)"
subtitle: "Sampling"
author: "Mansour Abdoli, PhD"
format:
  live-revealjs:
    slide-number: true
    incremental: true
    chalkboard: true
    preview-links: true
    code-overflow: wrap
    footer: "CourseKata Ch. 6- Sec 5 to 11"
engine: knitr
execute:
  echo: true
  warning: false
  message: false
output-files: CK-ch6_III.html
---

# Today: Normal Approximation & Applications

{{< include ./_extensions/r-wasm/live/_knitr.qmd >}}

```{r}
#| echo: false
knitr::opts_chunk$set(echo=FALSE)
suppressPackageStartupMessages({
  library(mosaic)
  library(ggformula)
})
def.par <- par(no.readonly = TRUE)
on.exit(par(def.par))

source('./assets/utils.R')
source('./assets/embedR.R')
source('./data/embedData.R')
load(file = "./data/Fingers.rda")
```

```{r}
#| echo: false
#| results: 'asis'
cat(embedR("./assets/utils.R"))
cat(embedData(Fingers))
```


```{webr}
#| echo: false
#| output: true
#| warning: false
#| message: false

library(mosaic)
library(ggformula)
options(digits = 3)

.webr_ready <- TRUE
set.seed(123)
```

## Session Goals

:::{.nonincremental}

By the end of today, you can:

* Find a Normal Approximation of an Empty-Model
* Evaluate the Normal Approximation
* Use the Normal Approximation to Estimate Event Propbabilities
* Compute Z-Score
* Use Z-Score and Probability to Compare Hypotheses

:::

## Empirical Rule is an Approximation
```{r}
#| fig-alt: 'Normal N(mu, sigma) with vertical lines at 1, 2, and 3 sigma away from mu'
#| fig-height: 3
xy <- within(
  data.frame(x=seq(-4, 5, length.out=100)),
  {y=dnorm(x)})
cols <- c('black','yellow','blue', 'green')
gf_area(y~x, data=xy, fill=cols[1]) |>
  gf_area(y~x, data=xy[abs(xy$x)<=3,], fill=cols[2]) |>
  gf_area(y~x, data=xy[abs(xy$x)<=2,], fill=cols[3]) |>
  gf_area(y~x, data=xy[abs(xy$x)<=1,], fill=cols[4]) |>
  gf_line(y~x, 
    data=data.frame(x=c(0, 0), y=c(0,dnorm(0))), color='red', size=1) |>
   gf_refine(
     scale_x_continuous(
    name = expression(X*"~"*"N("*mu*","*sigma*")"),
      breaks = -4:4,
      labels = c("", expression(mu-3*sigma), expression(mu-2*sigma), expression(mu-sigma), expression(mu), expression(mu+sigma), expression(mu+2*sigma), expression(mu+3*sigma), "")
    )
  ) + theme_bw() 

```

:::{.fragment .nonincremental}

```{r}
#| result: 'asis'
cat('- Area within 1 SD from the mean: ',
  diff(pnorm(c(-1,1))), 
  '\n- Area within 2 SD from the mean: ',
  diff(pnorm(c(-1,1)*2)),
  '\n- Area within 3 SD from the mean: ',
  diff(pnorm(c(-1,1)*3)), '\n')
```
:::


## Fitting a Normal to a Distribution

:::{style="font-size:.8em;"}
Student Thumb Length: 

```{webr}
#| fig-height: 2.25
#| fig-width: 5
mu <- mean(Fingers$Thumb)
sigma <- sd(Fingers$Thumb)

gf_dhistogram(~Thumb, data=Fingers, bins=10) |>
  gf_fitdistr(color = 'orange', linetype=2, linewidth=1.2) |>
  gf_vline(xintercept=mu, color='blue') |> 
  gf_labs(title=sprintf('Thumb Length: Mean=%0.1f, SD=%0.2f', mu, sigma))
```
:::

## Evaluate the Fit

:::{style="font-size:.8em;"}
Normal Approximation of Student Thumb Length: 

:::{.columns}
:::{.column}
::: {.nonincremental style="font-size:.8em;"}

- Recall Empirical Rule
  - $P(\mu-\sigma, \mu+\sigma)=68\%$
  - $P(\mu-2\sigma, \mu+2\sigma)=95\%$
  - $P(\mu-3\sigma, \mu+3\sigma)=99.7\%$
:::
:::
:::{.column}
:::{.fragment}

```{r}
#| fig-height: 2.2
#| fig-width: 5
#| fig-alt: 'Thumb-length histogram super imposed with a normal curve.'
#| fig-dpi: 300
#| fig-format: 'svg'
mu <- mean(Fingers$Thumb)
sigma <- sd(Fingers$Thumb)
gf_dhistogram(~Thumb, data=Fingers, bins=10) |>
  gf_fitdistr(color = 'black', linetype=1, linewidth=2) |>
  gf_segment(y1+y2~x1+x2, 
    data=data.frame(x1=mu+sigma*(-3:3),
    x2=mu+sigma*(-3:3), 
    y1=rep(0, 7), 
    y2=dnorm(mu+sigma*(-3:3), mu, sigma)),
    color=c('red', 'orange', 'purple', 'blue', 
      'purple', 'orange', 'red'), linewidth=1) |> 
  gf_labs(title=sprintf('Thumb Length: Mean=%0.1f, SD=%0.2f', mu, sigma)) + theme_bw()
```
:::
:::
:::

- Proportions:

:::{.fragment}

```{r}
cat('1-SD:', mean(Fingers$Thumb >= mu-sigma & Fingers$Thumb <= mu+sigma), '\t',
  '2-SD:', mean(Fingers$Thumb >= mu-2*sigma & Fingers$Thumb <= mu+2*sigma), '\t',
  '3-SD:', mean(Fingers$Thumb >= mu-3*sigma & Fingers$Thumb <= mu+3*sigma))
```
:::


- Not a Great Approximation; but OK!

:::

# Normal Distribution

## Generic vs Standard Normal

:::{.columns}
:::{.column}
:::{.nonincremental style='font-size:0.8em'}
- Recall Empirical Rule
  - $P(\mu-\sigma, \mu+\sigma)=68\%$
  - $P(\mu-2\sigma, \mu+2\sigma)=95\%$
  - $P(\mu-3\sigma, \mu+3\sigma)=99.7\%$
:::
:::
:::{.column}
:::{.fragment}
```{r}
#| fig-height: 3
#| fig-width: 5.5
#| alt-text: 'Normal distributions with two x-axis labels; one for Z~N(0,1) and the other for X~N(mu, siga)'
xy <- within(
  data.frame(x=seq(-4, 5, length.out=100)),
  {y=dnorm(x)})
cols <- c('black','yellow','blue', 'green')
gf_area(y~x, data=xy, fill=cols[1]) |>
  gf_area(y~x, data=xy[abs(xy$x)<=3,], fill=cols[2]) |>
  gf_area(y~x, data=xy[abs(xy$x)<=2,], fill=cols[3]) |>
  gf_area(y~x, data=xy[abs(xy$x)<=1,], fill=cols[4]) |>
  gf_line(y~x, 
    data=data.frame(x=c(0, 0), y=c(0,dnorm(0))), color='red', size=1) |>
   gf_refine(
     scale_x_continuous(
      breaks = NULL, labels = NULL, name =NULL
    )) |>
  #   name = expression(Z*"~"*"N(0,1)"),
  #   breaks = -4:4,
  #   labels = c('', -3:3, ""),
  #   # ,
  #   # sec.axis = sec_axis(
  #   #   ~ .,  # same scale transformation
  #   # name = expression(X*"~"*"N("*mu*","*sigma*")"),
  #   #   breaks = -4:4,
  #   #   labels = c("", expression(mu-3*sigma), expression(mu-2*sigma), expression(mu-sigma), expression(mu), expression(mu+sigma), expression(mu+2*sigma), expression(mu+3*sigma), "")
  #   # )
  # )) |>
  gf_text(y~x, #size = 6,
    data=data.frame(x=c(-4:4, 4.5), y=-dnorm(2.5)),
    label = c("", expression(mu-3*sigma), expression(mu-2*sigma), expression(mu-sigma), expression(mu), expression(mu+sigma), expression(mu+2*sigma), expression(mu+3*sigma), "",
    expression(X*"~"*"N("*mu*","*sigma*")")),
  ) |>
  gf_text(y~x, #size = 6,
    data=data.frame(x=c(-4:4, 4.5), y=-dnorm(2)),
    label = c("", -3:3, "",
    expression(Z*"~"*"N("*0*","*1*")")),
  ) + theme_bw() 

```
:::
:::
:::

:::{style="font-size: .8em;"}
- Each Normal is equivalent to Standard Normal

::: {.fragment}

$$X\sim N(\mu, \sigma) \Leftrightarrow Z\sim N(0, 1)$$

$$X = \mu + Z\cdot \sigma \Leftrightarrow Z=\frac{X-\mu}{\sigma}$$

:::
:::

# Standardization

## Interpretation of $Z$

- $Z=\frac{X-\mu}{\sigma}$: 
  \ 
  $X$ is $Z$-many standard deviation above $\mu$
  
- Example: $T\sim N(75, 5)$:
  - $T=82$ is $1.4 (=\frac{82-75}{5})$ standard deviation above the mean.

## Application of $Z$: Within Group Comparison

:::{.nonincremental style="font-size:.8em"}
- Which one is taller in their group:
  - A 66-inch female student
  - A 72-inch female student

:::

:::{.columns}
:::{.column}
:::{.fragment}

```{r}
#| fig-height: 3
#| fig-width: 5
heights <-c(68, 72)
HGmodel <- lm(Height~Gender, data=Fingers)
HGmeans <- mean(Height~Gender, data=Fingers)
gf_dhistogram(~Height, data=Fingers, fill=~Gender) |>
  gf_fitdistr() |> 
  coursekata::gf_model(HGmodel, color='blue') |>
  gf_vline(xintercept=~Height,
    data=data.frame(Height=heights, 
    Gender=names(HGmeans)),
  inherit = FALSE, color='red') |>
  gf_facet_grid(Gender~.)
```
:::

:::
:::{.column}
:::{.fragment}

```{r}
HGmeans <- mean(Height~Gender, data=Fingers)
HGsd <- sd(Height~Gender, data=Fingers)
cat(sprintf('Female: Z = (%0.2f-%0.2f)/(%0.3f) = %0.3f', 
  heights[1], HGmeans['female'], HGsd['female'], 
  (heights[1]- HGmeans['female'])/HGsd['female']), '\n',
  sprintf('Male: Z = (%0.2f-%0.2f)/(%0.3f) = %0.3f', 
  heights[2], HGmeans['male'], HGsd['male'], 
  (heights[2]- HGmeans['male'])/HGsd['male']), '\n', sep='')
```

:::
:::
:::

## Application of $Z$: Between Group Decision

:::{.nonincremental style="font-size:.8em"}

- A student is 68 inches; is the student male or female?

:::

:::{.columns}
:::{.column}
:::{.fragment}

```{r}
#| fig-height: 3
#| fig-width: 5
height <-c(68)
HGmodel <- lm(Height~Gender, data=Fingers)
HGmeans <- mean(Height~Gender, data=Fingers)
gf_dhistogram(~Height, data=Fingers, fill=~Gender) |>
  gf_fitdistr() |> 
  coursekata::gf_model(HGmodel, color='blue') |>
  gf_vline(xintercept=height,
  inherit = FALSE, color='red') |>
  gf_facet_grid(Gender~.)
```

:::
:::
:::{.column}

- Which is more unlikely?
  - From female group? $P(Height > 68)$
  - From male group? $P(Height < 68)$

:::{.fragment}

```{r, result='asis'}
cat(sprintf('P(Female>68): %0.4f', 
  mean(Fingers$Height>68 & Fingers$Gender=='female')), '\n',
  sprintf('P(Male<68): %0.4f', 
  mean(Fingers$Height<68 & 
    Fingers$Gender=='male')), '\n', sep='')
```
:::

:::
:::

